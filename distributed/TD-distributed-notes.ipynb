{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "https://www.tensorflow.org/deploy/distributed\n",
    "https://github.com/hn826/distributed-tensorflow\n",
    "https://medium.com/clusterone/how-to-write-distributed-tensorflow-code-with-an-example-on-tensorport-70bf3306adcb\n",
    "https://www.oreilly.com/ideas/distributed-tensorflow\n",
    "https://github.com/tmulc18/Distributed-TensorFlow-Guide/tree/master/Multiple-GPUs-Single-Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies for distributed learning\n",
    "## Model Parallelism\n",
    "When the model is too big to fit into memory on one machine, one can assign different parts of the graph to different machines. The parameters will live on that machine, and their training and update operations will happen there.\n",
    "\n",
    "## Data Parallelism\n",
    "The entire graph will live on one machine called the **parameter server (ps)**. If the amount of I/O becomes to large for a single parameter server it can be replicated, a copy of the entire graph can live on several parameter servers that stay in sync.\n",
    "\n",
    "Training operations will be executed on multiple machines called **workers**. Each worker will be reading different data batches, computing gradients, and sending update to the parameter servers. Usually the workers will average there gradients and only a single update will be sent to the parameter server.\n",
    "\n",
    "  * **Synchronous training:** The worker will synchronize there work. At any point in time, two workers have the exact same graph parameters values.\n",
    "  * **Asynchronous training:** The workers will work asynchronously. At any point in time, two workers might have different graph parameters values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has three types of nodes:\n",
    " * One or more **parameter servers** that host the graph\n",
    " * A **master worker** coordinates the training operations, and takes care of initializing the model, saving and restoring model checkpoints and saving summaries for TensorBoard. The master worker also takes care of fault-tolerance (if one ps or a worker crashes)\n",
    " * **workers** (including the master worker) handle compute training steps and send updates to the parameter servers\n",
    " \n",
    "The reason you might want to have more than one parameter server is to handle a large volume of I/O from the workers. \n",
    "\n",
    "Setting up distributed TensorFlow requires the following steps:\n",
    " * Define the `tf.trainClusterSpec` and `tf.train.Server`\n",
    " * Assign the graph to the parameter servers and workers\n",
    " * Configure and launch a `tf.train.MonitoredTrainingSession`\n",
    " \n",
    "A `tf.train.ClusterSpec` represents the set of processes that participate in a distributed TensorFlow computation.\n",
    "\n",
    "Every `tf.train.Server` belongs to a particular cluster. A `tf.train.Server` instance encapsulates a set of devices and corresponds to a particular task in a named job. The server can communicate with any other server in the same cluster.\n",
    "\n",
    "Using the `with tf.device` command, you can now assign nodes (either ops or variables) to a specific task of a specific job.\n",
    "\n",
    "In the data parallelism framework, variable operations will be assigned to parameter servers and training operations to workers.\n",
    "\n",
    "TensorFlow provides a convenient `tf.train.replica_device_setter` that automatically takes care of assigning operations to devices:\n",
    "\n",
    "\n",
    "    with tf.device(tf.train.replica_device_setter(cluster_spec)):\n",
    "        # define graph...\n",
    "        # define training operations...\n",
    "        \n",
    "`tf.train.MonitoredTrainingSession` is the equivalent of `tf.Session` for distributed training. It takes care of setting up a master worker node, that will handle:\n",
    "  * Initializing the graph\n",
    "  * Create checkpoints\n",
    "  * Exporting TensorBoard summaries\n",
    "  * Starting / stopping the session\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
